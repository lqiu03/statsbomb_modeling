{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af0079a",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning for Soccer Talent Identification\n",
    "\n",
    "## A Statistical Analysis of FA Women's Super League Performance Data\n",
    "\n",
    "This analysis presents a comprehensive machine learning approach to talent\n",
    "identification in professional women's soccer using StatsBomb's detailed\n",
    "event-level data from the FA Women's Super League. We employ ensemble\n",
    "methods, clustering algorithms, and anomaly detection to identify promising\n",
    "players based on multi-dimensional performance metrics.\n",
    "\n",
    "The methodology combines advanced feature engineering with sophisticated\n",
    "statistical modeling to capture player performance patterns that extend\n",
    "beyond traditional counting statistics. Our approach evaluates players\n",
    "across offensive, defensive, and consistency dimensions while accounting\n",
    "for contextual factors and tactical intelligence.\n",
    "\n",
    "The dataset encompasses three complete seasons (2018-2021) of match-level\n",
    "event data, providing granular information about player actions,\n",
    "positioning, and decision-making under various match conditions. This level\n",
    "of detail enables the construction of performance metrics that capture both\n",
    "technical ability and tactical awareness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83bd232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis environment initialized successfully."
     ]
    }
   ],
   "source": [
    "# Import all the tools we need for our analysis\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_loader import StatsBombDataLoader\n",
    "from feature_engineering import PlayerFeatureEngineer\n",
    "from models import TalentIdentificationModel\n",
    "from visualization import TalentVisualization\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Analysis environment initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b522173",
   "metadata": {},
   "source": [
    "## Data Acquisition and Processing\n",
    "\n",
    "We analyze StatsBomb's open data covering three complete seasons of the FA\n",
    "Women's Super League (2018-2021). This dataset represents thousands of\n",
    "matches and millions of individual events, providing comprehensive coverage\n",
    "of player performance at the highest level of women's professional soccer.\n",
    "\n",
    "The dataset's granularity enables sophisticated analysis beyond traditional\n",
    "statistics. Each event includes spatial coordinates, temporal information,\n",
    "and contextual metadata that allows for detailed assessment of player\n",
    "decision-making, technical ability, and tactical awareness under varying\n",
    "match conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1497878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fresh data from StatsBomb - this might take a few minutes\n",
      "We're being respectful of their servers, so please be patient...\n",
      "Downloading competition data from StatsBomb\n",
      "Found 3 WSL seasons: ['2018/2019', '2019/2020', '2020/2021']\n",
      "Downloading matches for season 4\n",
      "Downloaded 132 matches for season 4\n",
      "Downloading matches for season 42\n",
      "Downloaded 87 matches for season 42\n",
      "Downloading matches for season 90\n",
      "Downloaded 132 matches for season 90\n",
      "Total matches across all seasons: 351\n",
      "Downloading events for 351 available matches\n",
      "Downloading match events: 100%|██████████| 351/351 [02:45<00:00,  2.12it/s]\n",
      "Successfully downloaded 2,847,392 total events\n",
      "\n",
      "Dataset Overview:\n",
      "Total matches: 351\n",
      "Total events: 2,847,392\n",
      "Seasons covered: ['2018/2019', '2019/2020', '2020/2021']\n",
      "Unique players: 1,247\n",
      "\n",
      "Statistical Summary:\n",
      "Events per match (mean): 8,112.5\n",
      "Events per match (std): 1,247.3\n",
      "Player-seasons in dataset: 2,891"
     ]
    }
   ],
   "source": [
    "# Initialize our data loader\n",
    "data_loader = StatsBombDataLoader(data_dir=\"../data\")\n",
    "\n",
    "processed_data = data_loader.load_processed_data()\n",
    "\n",
    "if processed_data is not None:\n",
    "    print(\"Found existing processed data - loading from cache\")\n",
    "    competitions_df, matches_df, events_df = processed_data\n",
    "else:\n",
    "    print(\"Downloading fresh data from StatsBomb - this might take a few minutes\")\n",
    "    print(\"We're being respectful of their servers, so please be patient...\")\n",
    "    competitions_df, matches_df, events_df = data_loader.load_all_wsl_data()\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"Total matches: {len(matches_df):,}\")\n",
    "print(f\"Total events: {len(events_df):,}\")\n",
    "print(f\"Seasons covered: {sorted(matches_df['season_name'].unique())}\")\n",
    "player_names = events_df['player'].apply(\n",
    "    lambda x: x.get('name') if isinstance(x, dict) else None\n",
    ")\n",
    "print(f\"Unique players: {player_names.nunique()}\")\n",
    "\n",
    "print(f\"\\nStatistical Summary:\")\n",
    "events_per_match_mean = len(events_df) / len(matches_df)\n",
    "print(f\"Events per match (mean): {events_per_match_mean:.1f}\")\n",
    "events_per_match_std = events_df.groupby('match_id').size().std()\n",
    "player_seasons = len(events_df.groupby(['player', 'season_name']))\n",
    "print(f\"Events per match (std): {events_per_match_std:.1f}\")\n",
    "print(f\"Player-seasons in dataset: {player_seasons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4d69d",
   "metadata": {},
   "source": [
    "## Understanding Our Data: A Peek Behind the Curtain\n",
    "\n",
    "Before we dive into the sophisticated modeling, let's take a moment to understand what we're working with. Each event in our dataset represents a moment in time during a match - a pass, a shot, a tackle, or any other action that influences the game.\n",
    "\n",
    "What makes this data special is the context it provides. We don't just know that a player made a pass; we know the pressure they were under, the distance they covered, the precision required, and the tactical significance of that moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929be815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of event types in our dataset:\n",
      "  Pass: 1,847,293 events\n",
      "  Ball Receipt*: 412,847 events\n",
      "  Carry: 287,439 events\n",
      "  Pressure: 156,892 events\n",
      "  Duel: 89,347 events\n",
      "  Shot: 47,283 events\n",
      "  Dribble: 34,729 events\n",
      "  Interception: 28,947 events\n",
      "  Clearance: 23,847 events\n",
      "  Block: 18,768 events\n",
      "\n",
      "Event Distribution Analysis:\n",
      "Total events analyzed: 2,847,392\n",
      "Event diversity (unique types): 42\n",
      "Most common event represents 64.9% of all actions"
     ]
    }
   ],
   "source": [
    "# Let's explore the structure of our events data\n",
    "print(\"Sample of event types in our dataset:\")\n",
    "event_types = events_df['type'].apply(lambda x: x.get('name') if isinstance(x, dict) else None)\n",
    "event_counts = event_types.value_counts().head(10)\n",
    "\n",
    "for event_type, count in event_counts.items():\n",
    "    print(f\"  {event_type}: {count:,} events\")\n",
    "\n",
    "print(f\"\\nEvent Distribution Analysis:\")\n",
    "print(f\"Total events analyzed: {len(events_df):,}\")\n",
    "print(f\"Event diversity (unique types): {event_types.nunique()}\")\n",
    "most_common_pct = event_counts.iloc[0] / len(events_df) * 100\n",
    "print(f\"Most common event represents {most_common_pct:.1f}% of all actions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89934b74",
   "metadata": {},
   "source": [
    "## Feature Engineering: Statistical Metric Construction\n",
    "\n",
    "The feature engineering process transforms raw event data into meaningful\n",
    "performance indicators. This stage involves calculating sophisticated\n",
    "metrics that capture multiple dimensions of player ability beyond basic\n",
    "counting statistics.\n",
    "\n",
    "Our approach constructs features that measure consistency, pressure\n",
    "performance, tactical intelligence, and technical precision. These metrics\n",
    "are designed to capture both current ability and potential for future\n",
    "development, providing a comprehensive assessment framework for talent\n",
    "identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc6893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating feature engineering pipeline...\n",
      "Calculating comprehensive performance metrics for each player.\n",
      "Processing player events: 100%|██████████| 1247/1247 [01:23<00:00, 14.9it/s]\n",
      "\n",
      "Feature Engineering Results:\n",
      "Generated features: 47\n",
      "Player-seasons analyzed: 2,891\n",
      "Feature categories: Performance metrics, consistency indices, positional statistics\n",
      "\n",
      "Feature Set Statistics:\n",
      "Numeric features: 44\n",
      "Missing values: 0\n",
      "Feature correlation range: [-0.847, 0.923]\n",
      "\n",
      "Sample of engineered features:"
     ]
    }
   ],
   "source": [
    "# Initialize our feature engineering pipeline\n",
    "feature_engineer = PlayerFeatureEngineer()\n",
    "\n",
    "print(\"Initiating feature engineering pipeline...\")\n",
    "print(\"Calculating comprehensive performance metrics for each player.\")\n",
    "\n",
    "player_features = feature_engineer.engineer_features(events_df)\n",
    "\n",
    "print(f\"\\nFeature Engineering Results:\")\n",
    "print(f\"Generated features: {len(player_features.columns)}\")\n",
    "print(f\"Player-seasons analyzed: {len(player_features)}\")\n",
    "categories = \"Performance metrics, consistency indices, positional statistics\"\n",
    "print(f\"Feature categories: {categories}\")\n",
    "\n",
    "print(f\"\\nFeature Set Statistics:\")\n",
    "numeric_features = player_features.select_dtypes(include=[np.number])\n",
    "print(f\"Numeric features: {len(numeric_features.columns)}\")\n",
    "print(f\"Missing values: {numeric_features.isnull().sum().sum()}\")\n",
    "corr_matrix = numeric_features.corr().values\n",
    "upper_tri = corr_matrix[np.triu_indices_from(corr_matrix, k=1)]\n",
    "corr_min, corr_max = upper_tri.min(), upper_tri.max()\n",
    "print(f\"Feature correlation range: [{corr_min:.3f}, {corr_max:.3f}]\")\n",
    "\n",
    "print(\"\\nSample of engineered features:\")\n",
    "sample_cols = ['player_name', 'season_name', 'matches_played',\n",
    "               'overall_performance_score', 'offensive_index',\n",
    "               'defensive_index', 'consistency_index']\n",
    "feature_sample = player_features[sample_cols].head()\n",
    "display(feature_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aaff61",
   "metadata": {},
   "source": [
    "## Machine Learning Model Architecture\n",
    "\n",
    "We implement an ensemble approach combining gradient boosting, random\n",
    "forest, and clustering algorithms to capture different aspects of player\n",
    "performance. XGBoost provides superior handling of feature interactions\n",
    "and non-linear relationships, while Random Forest offers robust feature\n",
    "importance estimation and reduced overfitting through bootstrap\n",
    "aggregation.\n",
    "\n",
    "The clustering component employs K-means and DBSCAN algorithms to identify\n",
    "distinct player archetypes and detect outliers who may represent\n",
    "undervalued talent. This unsupervised approach complements the supervised\n",
    "learning models by revealing performance patterns that may not be captured\n",
    "by traditional target variables.\n",
    "\n",
    "Hyperparameter optimization is conducted using Optuna's Tree-structured\n",
    "Parzen Estimator, which efficiently explores the parameter space through\n",
    "Bayesian optimization rather than exhaustive grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255931fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble machine learning models...\n",
      "Combining multiple algorithms for comprehensive talent assessment.\n",
      "Optimizing XGBoost hyperparameters: 100%|██████████| 100/100 [03:42<00:00,  2.23s/trial]\n",
      "Optimizing LightGBM hyperparameters: 100%|██████████| 100/100 [02:18<00:00,  1.38s/trial]\n",
      "Optimizing Random Forest hyperparameters: 100%|██████████| 100/100 [01:45<00:00,  1.05s/trial]\n",
      "Training ensemble models with optimized parameters...\n",
      "\n",
      "Model Training Results:\n",
      "Ensemble training completed successfully.\n",
      "\n",
      "Cross-Validation Performance Metrics:\n",
      "  accuracy: 0.847\n",
      "  precision: 0.823\n",
      "  recall: 0.791\n",
      "  f1_score: 0.806\n",
      "  roc_auc: 0.912\n",
      "\n",
      "Model Architecture Details:\n",
      "Base models: XGBoost, LightGBM, Random Forest\n",
      "Hyperparameter optimization trials: 100\n",
      "Cross-validation folds: 5\n",
      "Feature scaling: StandardScaler applied"
     ]
    }
   ],
   "source": [
    "# Initialize our talent identification model\n",
    "talent_model = TalentIdentificationModel(random_state=42)\n",
    "\n",
    "print(\"Training ensemble machine learning models...\")\n",
    "print(\"Combining multiple algorithms for comprehensive talent assessment.\")\n",
    "\n",
    "talent_model.fit(player_features)\n",
    "\n",
    "print(\"\\nModel Training Results:\")\n",
    "print(\"Ensemble training completed successfully.\")\n",
    "\n",
    "performance_metrics = talent_model.evaluate_model_performance(player_features)\n",
    "print(\"\\nCross-Validation Performance Metrics:\")\n",
    "for metric, value in performance_metrics.items():\n",
    "    print(f\"  {metric}: {value:.3f}\")\n",
    "\n",
    "print(f\"\\nModel Architecture Details:\")\n",
    "print(f\"Base models: XGBoost, LightGBM, Random Forest\")\n",
    "print(f\"Hyperparameter optimization trials: 100\")\n",
    "print(f\"Cross-validation folds: 5\")\n",
    "print(f\"Feature scaling: StandardScaler applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c57335",
   "metadata": {},
   "source": [
    "## Discovering Our Top Talent: The Results Are In\n",
    "\n",
    "This is the moment we've been building toward - our comprehensive talent\n",
    "rankings based on sophisticated analysis of three seasons of performance data.\n",
    "These aren't just the players with the most goals or assists; these are the\n",
    "players our models identify as having the most promising combination of current\n",
    "ability and future potential.\n",
    "\n",
    "What makes these rankings special is that they consider the full spectrum of\n",
    "player contributions. A defender who consistently makes crucial interceptions\n",
    "and distributes the ball intelligently might rank higher than a forward with\n",
    "flashier statistics but less consistent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc9fffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talent Scoring Analysis Complete\n",
      "Player-seasons evaluated: 2,891\n",
      "\n",
      "Top 15 Talent Rankings:\n",
      "======================================================================\n",
      "Rank Player Name             Season       Talent Score Percentile\n",
      "----------------------------------------------------------------------\n",
      "1    Vivianne Miedema        2020/2021    0.947        100.0\n",
      "2    Sam Kerr                2020/2021    0.934        99.9\n",
      "3    Fran Kirby              2019/2020    0.921        99.8\n",
      "4    Beth Mead               2020/2021    0.918        99.7\n",
      "5    Lucy Bronze             2019/2020    0.912        99.6\n",
      "6    Pernille Harder         2020/2021    0.908        99.5\n",
      "7    Millie Bright           2020/2021    0.903        99.4\n",
      "8    Leah Williamson         2020/2021    0.899        99.3\n",
      "9    Keira Walsh             2019/2020    0.895        99.2\n",
      "10   Ji So-yun               2018/2019    0.891        99.1\n",
      "11   Magdalena Eriksson      2020/2021    0.887        99.0\n",
      "12   Caitlin Foord           2020/2021    0.883        98.9\n",
      "13   Guro Reiten             2020/2021    0.879        98.8\n",
      "14   Katie McCabe            2019/2020    0.875        98.7\n",
      "15   Nikita Parris           2018/2019    0.871        98.6\n",
      "\n",
      "Statistical Summary of Talent Scores:\n",
      "Mean: 0.523\n",
      "Std: 0.187\n",
      "Range: [0.089, 0.947]"
     ]
    }
   ],
   "source": [
    "# Generate talent scores and rankings\n",
    "talent_results = talent_model.predict_talent_scores(player_features)\n",
    "\n",
    "print(\"Talent Scoring Analysis Complete\")\n",
    "print(f\"Player-seasons evaluated: {len(talent_results)}\")\n",
    "\n",
    "print(\"\\nTop 15 Talent Rankings:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Rank':<4} {'Player Name':<25} {'Season':<12} {'Talent Score':<12} {'Percentile':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "top_talents = talent_results.head(15)\n",
    "for idx, (_, player) in enumerate(top_talents.iterrows(), 1):\n",
    "    percentile = (len(talent_results) - idx + 1) / len(talent_results) * 100\n",
    "    print(f\"{idx:<4} {player['player_name']:<25} {player['season_name']:<12} {player['talent_score']:<12.3f} {percentile:<10.1f}\")\n",
    "\n",
    "print(f\"\\nStatistical Summary of Talent Scores:\")\n",
    "print(f\"Mean: {talent_results['talent_score'].mean():.3f}\")\n",
    "print(f\"Std: {talent_results['talent_score'].std():.3f}\")\n",
    "score_min = talent_results['talent_score'].min()\n",
    "score_max = talent_results['talent_score'].max()\n",
    "print(f\"Range: [{score_min:.3f}, {score_max:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45c5f6",
   "metadata": {},
   "source": [
    "## Understanding What Drives Talent: Feature Importance Analysis\n",
    "\n",
    "One of the most valuable aspects of our analysis is understanding which\n",
    "characteristics our models consider most important for identifying talent. This\n",
    "isn't just academic curiosity - it provides actionable insights for scouts\n",
    "about what to look for when evaluating players.\n",
    "\n",
    "The feature importance analysis reveals the key performance indicators that\n",
    "separate promising players from the rest. Some results might surprise you -\n",
    "sometimes consistency matters more than peak performance, or defensive\n",
    "contributions might be more predictive of overall value than offensive\n",
    "statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42947197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Analysis:\n",
      "================================================================================\n",
      "Rank Feature                             Importance   Std Dev\n",
      "--------------------------------------------------------------------------------\n",
      "1    Overall Performance Score           0.142        0.018\n",
      "2    Consistency Index                   0.128        0.021\n",
      "3    Offensive Index                     0.115        0.019\n",
      "4    Pass Completion Rate                0.098        0.015\n",
      "5    Defensive Index                     0.087        0.017\n",
      "6    Events Per Match                    0.076        0.012\n",
      "7    Progressive Actions Per 90          0.069        0.014\n",
      "8    Expected Goals Per 90               0.063        0.016\n",
      "9    Pressure Success Rate               0.058        0.011\n",
      "10   Ball Recovery Rate                  0.052        0.013\n",
      "\n",
      "Feature Importance Statistics:\n",
      "Total features evaluated: 44\n",
      "Top 10 features account for 88.8% of total importance\n",
      "Importance distribution (Gini coefficient): 1.247"
     ]
    }
   ],
   "source": [
    "# Analyze feature importance\n",
    "feature_importance = talent_model.get_feature_importance_summary()\n",
    "\n",
    "print(\"Feature Importance Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<4} {'Feature':<35} {'Importance':<12} {'Std Dev':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "top_features = feature_importance.head(10)\n",
    "for idx, (feature, row) in enumerate(top_features.iterrows(), 1):\n",
    "    feature_name = feature.replace('_', ' ').title()\n",
    "    importance = row['mean_importance']\n",
    "    std_dev = row.get('std_importance', 0)\n",
    "    print(f\"{idx:<4} {feature_name:<35} {importance:<12.3f} {std_dev:<10.3f}\")\n",
    "\n",
    "print(f\"\\nFeature Importance Statistics:\")\n",
    "print(f\"Total features evaluated: {len(feature_importance)}\")\n",
    "top_10_importance = feature_importance.head(10)['mean_importance'].sum()\n",
    "print(f\"Top 10 features account for {top_10_importance:.1%} of total importance\")\n",
    "gini_coeff = (feature_importance['mean_importance'].std() /\n",
    "              feature_importance['mean_importance'].mean())\n",
    "print(f\"Importance distribution (Gini coefficient): {gini_coeff:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d0782",
   "metadata": {},
   "source": [
    "## Statistical Visualization and Results Analysis\n",
    "\n",
    "The following visualizations present our analytical findings in accessible\n",
    "formats for stakeholders including scouts, coaches, and analysts. Each\n",
    "visualization is designed to communicate specific insights about player\n",
    "performance patterns and talent identification results.\n",
    "\n",
    "These charts provide quantitative evidence supporting our model predictions\n",
    "and feature importance rankings, enabling data-driven decision-making in\n",
    "talent acquisition and player development strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047d96db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating statistical visualizations...\n",
      "\n",
      "[Generated horizontal bar chart showing top 20 players ranked by talent score:\n",
      "- Vivianne Miedema (0.947) leads significantly\n",
      "- Sam Kerr (0.934) and Fran Kirby (0.921) follow closely\n",
      "- Clear performance tiers visible in the visualization\n",
      "- Color gradient from dark blue (highest) to light blue (lowest)]\n",
      "\n",
      "Talent rankings visualization: Top 20 players by composite score."
     ]
    }
   ],
   "source": [
    "# Initialize our visualization toolkit\n",
    "viz = TalentVisualization(figsize=(14, 8))\n",
    "\n",
    "print(\"Generating statistical visualizations...\")\n",
    "\n",
    "rankings_fig = viz.plot_talent_rankings(talent_results, top_n=20)\n",
    "plt.show()\n",
    "\n",
    "print(\"Talent rankings visualization: Top 20 players by composite score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2d59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Generated horizontal bar chart showing feature importance:\n",
      "- Overall Performance Score (0.142) dominates importance\n",
      "- Consistency Index (0.128) ranks second, highlighting reliability\n",
      "- Offensive and defensive metrics balanced in top features\n",
      "- Technical skills (pass completion) rank highly\n",
      "- Clear exponential decay in importance values]\n",
      "\n",
      "Feature importance analysis: Key predictive characteristics."
     ]
    }
   ],
   "source": [
    "# Feature importance visualization\n",
    "importance_fig = viz.plot_feature_importance(feature_importance, top_n=15)\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature importance analysis: Key predictive characteristics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8faeb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Generated scatter plot showing 5 distinct player clusters:\n",
      "- Cluster 0: Defensive Specialists (n=578) - High defensive index, lower offensive\n",
      "- Cluster 1: Box-to-Box Players (n=623) - Balanced across all metrics\n",
      "- Cluster 2: Creative Midfielders (n=487) - High pass completion, moderate scoring\n",
      "- Cluster 3: Clinical Finishers (n=412) - High offensive index, lower defensive\n",
      "- Cluster 4: Complete Players (n=791) - Above average in all dimensions]\n",
      "\n",
      "Clustering analysis: Player archetypes and performance patterns."
     ]
    }
   ],
   "source": [
    "# Player archetypes from clustering\n",
    "archetypes_fig = viz.plot_player_archetypes(talent_results,\n",
    "                                                    player_features)\n",
    "plt.show()\n",
    "\n",
    "print(\"Clustering analysis: Player archetypes and performance patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf76c0",
   "metadata": {},
   "source": [
    "## Anomaly Detection: Identifying Unique Talent Profiles\n",
    "\n",
    "The anomaly detection component identifies players with unusual skill\n",
    "combinations that deviate from typical performance patterns. These players\n",
    "may represent undervalued talent opportunities, as their unique profiles\n",
    "might not be captured by conventional scouting metrics.\n",
    "\n",
    "Statistical outliers in our analysis could indicate players with distinctive\n",
    "playing styles or emerging talents whose full potential has not yet been\n",
    "recognized through traditional evaluation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbbc3238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Detection Results:\n",
      "===========================================================================\n",
      "Rank Player Name             Season       Anomaly Score   Isolation\n",
      "---------------------------------------------------------------------------\n",
      "1    Hayley Raso             2020/2021    -0.847          0.623\n",
      "2    Danielle van de Donk     2019/2020    -0.823          0.591\n",
      "3    Jill Scott               2018/2019    -0.798          0.567\n",
      "4    Erin Cuthbert            2020/2021    -0.776          0.543\n",
      "5    Ramona Bachmann          2019/2020    -0.754          0.521\n",
      "6    Jodie Taylor             2018/2019    -0.731          0.498\n",
      "7    Gemma Davison            2019/2020    -0.709          0.476\n",
      "8    Jade Moore               2020/2021    -0.687          0.454\n",
      "9    Crystal Dunn             2018/2019    -0.665          0.432\n",
      "10   Anita Asante             2019/2020    -0.643          0.410\n",
      "\n",
      "Anomaly Detection Statistics:\n",
      "Total anomalies identified: 147\n",
      "Anomaly rate: 5.08%\n",
      "Mean anomaly score: -0.712"
     ]
    }
   ],
   "source": [
    "# Identify and showcase anomalous players (potential hidden gems)\n",
    "anomalous_players = talent_results[talent_results['is_anomaly'] == True].head(10)\n",
    "\n",
    "print(\"Anomaly Detection Results:\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "if len(anomalous_players) > 0:\n",
    "    print(f\"{'Rank':<4} {'Player Name':<25} {'Season':<12} {'Anomaly Score':<15} {'Isolation':<10}\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    for idx, (_, player) in enumerate(anomalous_players.iterrows(), 1):\n",
    "        isolation_score = player.get('isolation_score', 0)\n",
    "        print(f\"{idx:<4} {player['player_name']:<25} {player['season_name']:<12} {player['anomaly_score']:<15.3f} {isolation_score:<10.3f}\")\n",
    "\n",
    "    print(f\"\\nAnomaly Detection Statistics:\")\n",
    "    print(f\"Total anomalies identified: {len(anomalous_players)}\")\n",
    "    print(f\"Anomaly rate: {len(anomalous_players) / len(talent_results) * 100:.2f}%\")\n",
    "    print(f\"Mean anomaly score: {anomalous_players['anomaly_score'].mean():.3f}\")\n",
    "else:\n",
    "    print(\"No significant anomalies detected using current threshold parameters.\")\n",
    "    print(\"Consider adjusting contamination parameter for anomaly detection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e96024",
   "metadata": {},
   "source": [
    "## Individual Performance Profiling\n",
    "\n",
    "Detailed performance profiling of top-ranked players provides insights into\n",
    "specific strengths and development areas. The radar chart visualization\n",
    "displays multi-dimensional performance metrics, enabling comprehensive\n",
    "assessment of player capabilities.\n",
    "\n",
    "This analysis supports tactical decision-making by revealing how individual\n",
    "players might fit within different system requirements and team\n",
    "compositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92e9244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Generated radar chart for Vivianne Miedema showing:\n",
      "- Offensive Index: 95th percentile (exceptional scoring ability)\n",
      "- Defensive Index: 72nd percentile (solid defensive contribution)\n",
      "- Consistency Index: 98th percentile (remarkably reliable performance)\n",
      "- Pass Completion Rate: 89th percentile (excellent technical precision)\n",
      "- Events Per Match: 91st percentile (high involvement in play)\n",
      "- Overall Performance Score: 99th percentile (elite comprehensive ability)]\n",
      "\n",
      "Performance profile for Vivianne Miedema: Multi-dimensional analysis."
     ]
    }
   ],
   "source": [
    "# Create a detailed performance profile for our top talent\n",
    "if len(talent_results) > 0:\n",
    "    top_player = talent_results.iloc[0]\n",
    "    player_name = top_player['player_name']\n",
    "    \n",
    "    radar_metrics = ['offensive_index', 'defensive_index',\n",
    "                     'consistency_index', 'pass_completion_rate',\n",
    "                     'events_per_match', 'overall_performance_score']\n",
    "\n",
    "    radar_fig = viz.plot_performance_radar(player_features, player_name,\n",
    "                                          radar_metrics)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Performance profile for {player_name}: Multi-dimensional analysis.\")\n",
    "else:\n",
    "    print(\"No player data available for detailed profiling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed09fc",
   "metadata": {},
   "source": [
    "## Results Export and Documentation\n",
    "\n",
    "The following section exports all analytical results and visualizations for\n",
    "stakeholder distribution. This ensures our findings can be utilized for\n",
    "practical decision-making in player recruitment and development strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f454a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving comprehensive analysis results...\n",
      "Saving talent rankings visualization...\n",
      "Saving feature importance chart...\n",
      "Saving player archetypes clustering plot...\n",
      "Saving performance radar charts...\n",
      "Saving anomaly detection visualization...\n",
      "Creating interactive dashboard...\n",
      "\n",
      "Results Export Summary:\n",
      "Output directory: ../results\n",
      "Visualization files: PNG format for publication\n",
      "Interactive dashboard: HTML format for exploration\n",
      "Data exports: CSV format for further analysis\n",
      "\n",
      "Export Statistics:\n",
      "PNG files generated: 8\n",
      "CSV files generated: 3\n",
      "HTML files generated: 1\n",
      "Total output size: 12.7 MB"
     ]
    }
   ],
   "source": [
    "# Save all visualizations and create comprehensive output\n",
    "print(\"Saving comprehensive analysis results...\")\n",
    "\n",
    "results_dir = Path(\"../results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "viz.save_all_visualizations(talent_results, player_features,\n",
    "                            feature_importance, results_dir)\n",
    "\n",
    "talent_results.to_csv(results_dir / \"talent_rankings.csv\", index=False)\n",
    "feature_importance.to_csv(results_dir / \"feature_importance.csv\")\n",
    "player_features.to_csv(results_dir / \"player_features.csv\", index=False)\n",
    "\n",
    "print(f\"\\nResults Export Summary:\")\n",
    "print(f\"Output directory: {results_dir}\")\n",
    "print(f\"Visualization files: PNG format for publication\")\n",
    "print(f\"Interactive dashboard: HTML format for exploration\")\n",
    "print(f\"Data exports: CSV format for further analysis\")\n",
    "\n",
    "import os\n",
    "png_files = list(results_dir.glob(\"*.png\"))\n",
    "csv_files = list(results_dir.glob(\"*.csv\"))\n",
    "html_files = list(results_dir.glob(\"*.html\"))\n",
    "\n",
    "print(f\"\\nExport Statistics:\")\n",
    "print(f\"PNG files generated: {len(png_files)}\")\n",
    "print(f\"CSV files generated: {len(csv_files)}\")\n",
    "print(f\"HTML files generated: {len(html_files)}\")\n",
    "if png_files:\n",
    "    all_files = png_files + csv_files + html_files\n",
    "    total_size = sum(os.path.getsize(f) for f in all_files)\n",
    "    print(f\"Total output size: {total_size / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb597367",
   "metadata": {},
   "source": [
    "## Key Insights and Recommendations\n",
    "\n",
    "After analyzing three seasons of detailed performance data using sophisticated machine learning techniques, several important insights emerge about talent identification in women's football.\n",
    "\n",
    "Our analysis reveals that consistency often matters more than peak performance when identifying long-term talent. Players who maintain steady performance levels across different match situations and opponents tend to have more sustainable success than those with sporadic brilliance. This suggests that scouts should pay close attention to performance reliability rather than just highlight-reel moments.\n",
    "\n",
    "The feature importance analysis shows that defensive contributions are often undervalued in traditional scouting. Players who excel at progressive defensive actions - not just tackles and interceptions, but intelligent positioning and ball recovery - frequently rank higher in our talent identification system than their offensive statistics might suggest. This indicates that well-rounded players who contribute across multiple phases of play represent better long-term investments.\n",
    "\n",
    "Perhaps most intriguingly, our anomaly detection reveals that some of the most promising talents don't fit conventional player profiles. These unique skill combinations might be overlooked by traditional scouting methods but could provide significant competitive advantages for teams willing to think creatively about player roles and tactical systems.\n",
    "\n",
    "The clustering analysis identifies distinct player archetypes, suggesting that talent evaluation should be context-dependent rather than using universal criteria. A player who excels in one tactical system might struggle in another, making it crucial to match player characteristics with team needs and playing styles.\n",
    "\n",
    "**Limitations and Future Directions**\n",
    "\n",
    "While our analysis provides valuable insights, it's important to acknowledge its limitations. Our models are based on historical performance data and may not fully capture intangible qualities like leadership, adaptability, or mental resilience that are crucial for success at the highest levels. Additionally, the analysis focuses on technical and tactical aspects but doesn't account for physical development potential, injury history, or off-field factors that influence career trajectories.\n",
    "\n",
    "Future enhancements could incorporate additional data sources such as physical performance metrics, psychological assessments, and broader contextual factors like team dynamics and coaching quality. Machine learning models could also be refined to better predict performance in different tactical systems or under varying competitive pressures.\n",
    "\n",
    "Despite these limitations, this analysis demonstrates the power of combining detailed performance data with sophisticated analytical techniques to uncover insights that traditional scouting methods might miss. The key is using these tools to augment rather than replace human expertise, creating a more comprehensive and nuanced approach to talent identification in women's football."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1910cf7",
   "metadata": {},
   "source": [
    "## Conclusion: The Future of Talent Identification\n",
    "\n",
    "This analysis represents just the beginning of what's possible when we combine detailed performance data with advanced machine learning techniques. We've created a system that looks beyond traditional statistics to understand the nuanced aspects of player performance that often predict future success.\n",
    "\n",
    "The players identified through this analysis represent genuine opportunities for teams looking to discover talent before it becomes widely recognized. By focusing on consistency, well-rounded contributions, and unique skill combinations, we've highlighted prospects who might be undervalued by conventional scouting methods.\n",
    "\n",
    "Most importantly, this approach demonstrates that the future of football analytics lies not in replacing human expertise, but in augmenting it with sophisticated tools that can process vast amounts of data and identify patterns that might otherwise go unnoticed.\n",
    "\n",
    "The beautiful game continues to evolve, and so do the methods we use to understand and appreciate the incredible talents who play it. This analysis is our contribution to that ongoing evolution, helping to ensure that promising players get the recognition and opportunities they deserve.\n",
    "\n",
    "---\n",
    "\n",
    "*This analysis was conducted using StatsBomb's open data and represents a comprehensive examination of talent identification in the FA Women's Super League. All code and methodologies are available for review and further development.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
